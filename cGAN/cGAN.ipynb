{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, losses, optimizers\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the generator model\n",
    "def generator_model():\n",
    "    inputs = layers.Input(shape=(height, width, channels))\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "    # Add more convolutional layers\n",
    "    outputs = layers.Conv2D(channels, kernel_size=3, strides=1, padding='same', activation='tanh')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define the discriminator model\n",
    "def discriminator_model():\n",
    "    inputs = layers.Input(shape=(height, width, channels))\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "    # Add more convolutional layers\n",
    "    outputs = layers.Conv2D(1, kernel_size=3, strides=1, padding='same', activation='sigmoid')(x)\n",
    "    return Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator loss\n",
    "def generator_loss(fake_output, target_output, generated_output):\n",
    "    gen_loss = losses.BinaryCrossentropy()(fake_output, tf.ones_like(fake_output))  # Adversarial loss\n",
    "    content_loss = losses.MeanAbsoluteError()(target_output, generated_output)  # Content loss\n",
    "    return gen_loss + content_loss\n",
    "\n",
    "# Define the discriminator loss\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = losses.BinaryCrossentropy()(real_output, tf.ones_like(real_output))  # Loss for real images\n",
    "    fake_loss = losses.BinaryCrossentropy()(fake_output, tf.zeros_like(fake_output))  # Loss for fake images\n",
    "    return real_loss + fake_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000\n",
      "Epoch 10/10000\n",
      "Epoch 20/10000\n",
      "Epoch 30/10000\n",
      "Epoch 40/10000\n",
      "Epoch 50/10000\n",
      "Epoch 60/10000\n",
      "Epoch 70/10000\n",
      "Epoch 80/10000\n",
      "Epoch 90/10000\n",
      "Epoch 100/10000\n",
      "Epoch 110/10000\n",
      "Epoch 120/10000\n",
      "Epoch 130/10000\n",
      "Epoch 140/10000\n",
      "Epoch 150/10000\n",
      "Epoch 160/10000\n",
      "Epoch 170/10000\n",
      "Epoch 180/10000\n",
      "Epoch 190/10000\n",
      "Epoch 200/10000\n",
      "Epoch 210/10000\n",
      "Epoch 220/10000\n",
      "Epoch 230/10000\n",
      "Epoch 240/10000\n",
      "Epoch 250/10000\n",
      "Epoch 260/10000\n",
      "Epoch 270/10000\n",
      "Epoch 280/10000\n",
      "Epoch 290/10000\n",
      "Epoch 300/10000\n",
      "Epoch 310/10000\n",
      "Epoch 320/10000\n",
      "Epoch 330/10000\n",
      "Epoch 340/10000\n",
      "Epoch 350/10000\n",
      "Epoch 360/10000\n",
      "Epoch 370/10000\n",
      "Epoch 380/10000\n",
      "Epoch 390/10000\n",
      "Epoch 400/10000\n",
      "Epoch 410/10000\n",
      "Epoch 420/10000\n",
      "Epoch 430/10000\n",
      "Epoch 440/10000\n",
      "Epoch 450/10000\n",
      "Epoch 460/10000\n",
      "Epoch 470/10000\n",
      "Epoch 480/10000\n",
      "Epoch 490/10000\n",
      "Epoch 500/10000\n",
      "Epoch 510/10000\n",
      "Epoch 520/10000\n",
      "Epoch 530/10000\n",
      "Epoch 540/10000\n",
      "Epoch 550/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 77\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_good_lighting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_bad_lighting\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# Display training progress\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\CSE-AiD\\anaconda3\\envs\\mash_anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\CSE-AiD\\anaconda3\\envs\\mash_anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\CSE-AiD\\anaconda3\\envs\\mash_anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\CSE-AiD\\anaconda3\\envs\\mash_anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\CSE-AiD\\anaconda3\\envs\\mash_anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\CSE-AiD\\anaconda3\\envs\\mash_anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\CSE-AiD\\anaconda3\\envs\\mash_anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the generator model\n",
    "def generator_model():\n",
    "    inputs = layers.Input(shape=(height, width, channels))\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "    # Add more convolutional layers\n",
    "    outputs = layers.Conv2D(channels, kernel_size=3, strides=1, padding='same', activation='tanh')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define the discriminator model\n",
    "def discriminator_model():\n",
    "    inputs = layers.Input(shape=(height, width, channels))\n",
    "    x = layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu')(inputs)\n",
    "    # Add more convolutional layers\n",
    "    outputs = layers.Conv2D(1, kernel_size=3, strides=1, padding='same', activation='sigmoid')(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define the generator loss\n",
    "def generator_loss(fake_output, target_output, generated_output):\n",
    "    gen_loss = losses.BinaryCrossentropy()(fake_output, tf.ones_like(fake_output))  # Adversarial loss\n",
    "    content_loss = losses.MeanAbsoluteError()(target_output, generated_output)  # Content loss\n",
    "    return gen_loss + content_loss\n",
    "\n",
    "# Define the discriminator loss\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = losses.BinaryCrossentropy()(real_output, tf.ones_like(real_output))  # Loss for real images\n",
    "    fake_loss = losses.BinaryCrossentropy()(fake_output, tf.zeros_like(fake_output))  # Loss for fake images\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "# Define the training step\n",
    "@tf.function\n",
    "def train_step(input_image_real, input_image_fake):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_image_fake = generator(input_image_fake, training=True)\n",
    "\n",
    "        real_output = discriminator(input_image_real, training=True)\n",
    "        fake_output = discriminator(generated_image_fake, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output, input_image_real, generated_image_fake)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "# Define hyperparameters\n",
    "height, width, channels = 64, 64, 3  # Dimensions of input images\n",
    "epochs = 10000\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Load the two images\n",
    "image_path_good_lighting = 'good_lighting.jpg'\n",
    "image_path_bad_lighting = 'bad_lighting.jpg'\n",
    "image_good_lighting = tf.expand_dims(tf.image.decode_image(tf.io.read_file(image_path_good_lighting)), axis=0)\n",
    "image_bad_lighting = tf.expand_dims(tf.image.decode_image(tf.io.read_file(image_path_bad_lighting)), axis=0)\n",
    "\n",
    "# Resize images to the desired dimensions\n",
    "target_height, target_width = 64, 64\n",
    "image_good_lighting = tf.image.resize(image_good_lighting, (target_height, target_width))\n",
    "image_bad_lighting = tf.image.resize(image_bad_lighting, (target_height, target_width))\n",
    "\n",
    "# Normalize pixel values to range [-1, 1]\n",
    "image_good_lighting = (tf.cast(image_good_lighting, tf.float32) / 127.5) - 1.0\n",
    "image_bad_lighting = (tf.cast(image_bad_lighting, tf.float32) / 127.5) - 1.0\n",
    "\n",
    "# Create generator and discriminator models\n",
    "generator = generator_model()\n",
    "discriminator = discriminator_model()\n",
    "\n",
    "# Define optimizers\n",
    "generator_optimizer = optimizers.Adam(learning_rate)\n",
    "discriminator_optimizer = optimizers.Adam(learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    train_step(image_good_lighting, image_bad_lighting)\n",
    "    \n",
    "    # Display training progress\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "\n",
    "# Generate an improved image\n",
    "generated_image_fake = generator(image_bad_lighting, training=False)\n",
    "\n",
    "# Visualize the result and evaluate the model as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Generate an improved image\n",
    "generated_image_fake = generator(image_bad_lighting, training=False)\n",
    "\n",
    "# Convert the generated image from [-1, 1] range to [0, 1] range for display\n",
    "generated_image_fake = (generated_image_fake + 1.0) / 2.0\n",
    "\n",
    "# Display the generated image\n",
    "plt.imshow(generated_image_fake[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_path_good_lighting, image_path_bad_lighting, target_height, target_width):\n",
    "    # Load and preprocess the real image (good lighting)\n",
    "    image_good_lighting = Image.open(image_path_good_lighting).resize((target_width, target_height))\n",
    "    image_good_lighting = np.array(image_good_lighting) / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "    # Load and preprocess the fake image (bad lighting)\n",
    "    image_bad_lighting = Image.open(image_path_bad_lighting).resize((target_width, target_height))\n",
    "    image_bad_lighting = np.array(image_bad_lighting) / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "    return image_good_lighting, image_bad_lighting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_good_lighting = 'good_lighting.jpg'\n",
    "image_path_bad_lighting = 'bad_lighting.jpg'\n",
    "target_height = 64\n",
    "target_width = 64\n",
    "real_image, fake_image = load_images(image_path_good_lighting, image_path_bad_lighting, target_height, target_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load and preprocess the dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Assume you have a function load_dataset() to load the dataset and preprocess it\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Shuffle and batch the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mshuffle(buffer_size)\u001b[38;5;241m.\u001b[39mbatch(batch_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the dataset\n",
    "# Assume you have a function load_dataset() to load the dataset and preprocess it\n",
    "train_dataset = dataset\n",
    "# Shuffle and batch the dataset\n",
    "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size)\n",
    "\n",
    "# Define hyperparameters\n",
    "height, width, channels = 64, 64, 3  # Dimensions of input images\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.0002\n",
    "buffer_size = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create generator and discriminator models\n",
    "generator = generator_model()\n",
    "discriminator = discriminator_model()\n",
    "\n",
    "# Define optimizers\n",
    "generator_optimizer = optimizers.Adam(learning_rate)\n",
    "discriminator_optimizer = optimizers.Adam(learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for batch in train_dataset:\n",
    "        input_images, target_images = batch\n",
    "        train_step(input_images, target_images)\n",
    "    \n",
    "    # Display training progress\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}/{epochs}, Generator Loss: {gen_loss.numpy()}, Discriminator Loss: {disc_loss.numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images with improved lighting\n",
    "# Assume you have a function generate_images() to generate images with bad lighting\n",
    "input_images = generate_images()\n",
    "improved_images = generator(input_images, training=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
